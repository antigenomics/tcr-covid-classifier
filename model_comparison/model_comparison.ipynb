{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #\n",
    "import numpy as np #\n",
    "import pandas as pd #\n",
    "import multiprocessing as mp #\n",
    "from itertools import permutations #\n",
    "\n",
    "#-----CLASSIFIER------\n",
    "from sklearn.svm import SVC #\n",
    "from sklearn import metrics #\n",
    "from sklearn.ensemble import RandomForestClassifier #\n",
    "from sklearn.model_selection import RandomizedSearchCV #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FMBA_metadata \n",
      " COVID       1061\n",
      "healthy      433\n",
      "precovid     118\n",
      "unknown       27\n",
      "Name: COVID_status, dtype: int64\n",
      "\n",
      "Adaptive_metadata \n",
      " acute        1140\n",
      "recovered     239\n",
      "baseline       74\n",
      "exposed        26\n",
      "non-acute       4\n",
      "Name: COVID-19-status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#-----read FMBA metadata------\n",
    "FMBA_metadata=pd.read_csv(\"../fmba/fmba_metadata_edited.tsv\", sep=\",\",header=0, dtype = str)\n",
    "print(\"FMBA_metadata \\n\", FMBA_metadata.COVID_status.value_counts())\n",
    "\n",
    "#-----read Adaptive metadata------\n",
    "AB_metadata=pd.read_csv(\"../adaptive/adaptive-metadata-edited.tsv\",sep=\"\\t\")\n",
    "AB_metadata[\"sample_short_name\"]=AB_metadata[\"sample_name\"].apply(lambda x: x[:-5]) #remove _TCRB from end of names\n",
    "print(\"\\nAdaptive_metadata \\n\", AB_metadata[\"COVID-19-status\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fmba_COVID: 1061\n",
      "fmba_healthy: 433\n",
      "fmba_precovid: 118\n",
      "\n",
      "Adaptive_acute: 1140\n",
      "HIP: 665\n",
      "KECK: 120\n"
     ]
    }
   ],
   "source": [
    "#----METADATA-----\n",
    "#----select FMBA cohorts-----\n",
    "fmba_COVID=set(FMBA_metadata.loc[FMBA_metadata['COVID_status']=='COVID', \"name\"])\n",
    "print(\"fmba_COVID:\", len(fmba_COVID))\n",
    "fmba_healthy=set(FMBA_metadata.loc[FMBA_metadata['COVID_status']=='healthy', \"name\"])\n",
    "print(\"fmba_healthy:\", len(fmba_healthy))\n",
    "fmba_precovid=set(FMBA_metadata.loc[FMBA_metadata['COVID_status']=='precovid', \"name\"])\n",
    "print(\"fmba_precovid:\", len(fmba_precovid))\n",
    "\n",
    "#----select Adaptive cohorts-----\n",
    "adaptive_acute=set(AB_metadata.loc[AB_metadata[\"COVID-19-status\"]==\"acute\",\"sample_short_name\"])\n",
    "print(\"\\nAdaptive_acute:\",  len(adaptive_acute))\n",
    "HIP=set(pd.read_csv(\"/projects/fmba_covid/COV_V_usage_adjustment_count_equation_v3/HIP_functional_adjusted/metadata.txt\", sep=\"\\t\", header=None)[0])\n",
    "HIP={xT.split(\".\")[0] for xT in HIP}\n",
    "print(\"HIP:\",  len(HIP))\n",
    "KECK=set(pd.read_csv(\"/projects/fmba_covid/COV_V_usage_adjustment_count_equation_v3/KECK_functional_adjusted/metadata.txt\", sep=\"\\t\", header=None)[0])\n",
    "KECK={xT.split(\"_\")[0] for xT in KECK}\n",
    "print(\"KECK:\",  len(KECK))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020 10 19    566\n",
       "2020 12 18    377\n",
       "2020 09 05    192\n",
       "2020 09 28    191\n",
       "2020 09 27    189\n",
       "2021 01 07    118\n",
       "2021 02 13      6\n",
       "Name: sequencingDate, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-----sequencing runs-----\n",
    "FMBA_metadata[\"sequencingDate\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COVID-19-DLS                     433\n",
       "COVID-19-NIH/NIAID               357\n",
       "COVID-19-HUniv12Oct              177\n",
       "COVID-19-ISB                      69\n",
       "COVID-19-IRST/AUSL                64\n",
       "COVID-19-Adaptive                 37\n",
       "COVID-19-Adaptive-MIRAMatched      3\n",
       "Name: Dataset, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-----datasets-----\n",
    "AB_metadata=AB_metadata.loc[AB_metadata[\"COVID-19-status\"]==\"acute\"]\n",
    "AB_metadata[\"Dataset\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmba_set1_={\"2020 09 27\", \"2020 12 18\", \"2020 10 19\"}\n",
    "fmba_set2_={\"2020 09 05\", \"2020 09 28\", \"2021 01 07\"} # 2021 01 07==precovid\n",
    "fmba_set1_=set(FMBA_metadata.loc[FMBA_metadata[\"sequencingDate\"].isin(fmba_set1_), \"name\"])\n",
    "fmba_set2_=set(FMBA_metadata.loc[FMBA_metadata[\"sequencingDate\"].isin(fmba_set2_), \"name\"])\n",
    "\n",
    "adaptive_set1_={\"COVID-19-NIH/NIAID\", \"COVID-19-HUniv12Oct\", \"COVID-19-Adaptive\", \"KECK\"}\n",
    "adaptive_set2_={\"COVID-19-DLS\", \"COVID-19-ISB\", \"COVID-19-IRST/AUSL\", \"HIP\"}\n",
    "adaptive_set1_=set(AB_metadata.loc[AB_metadata[\"Dataset\"].isin(adaptive_set1_), \"sample_short_name\"]) | KECK\n",
    "adaptive_set2_=set(AB_metadata.loc[AB_metadata[\"Dataset\"].isin(adaptive_set2_), \"sample_short_name\"]) | HIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----read Adaptive and HIP data-----\n",
    "AB_data=pd.read_csv(\"../CDR3_code/BLOSUM62/UNWEIGHT_TABLES/Adaptive_top_2000AA/Adaptive_top_10000AA.tsv\",\n",
    "                    sep=\"\\t\", index_col=0)\n",
    "AB_data.index=[xT.split(\"_\")[0] for xT in AB_data.index]\n",
    "\n",
    "HIP_data=pd.read_csv(\"../CDR3_code/BLOSUM62/UNWEIGHT_TABLES/HIP_top_2000AA/HIP_top_10000AA.tsv\",\n",
    "                    sep=\"\\t\", index_col=0)\n",
    "HIP_data.index=[xT.split(\".\")[0] for xT in HIP_data.index]\n",
    "\n",
    "KECK_data=pd.read_csv(\"../CDR3_code/BLOSUM62/UNWEIGHT_TABLES/KECK_top_2000AA/KECK_top_10000AA.tsv\",\n",
    "                    sep=\"\\t\", index_col=0)\n",
    "KECK_data.index=[xT.split(\"_\")[0] for xT in KECK_data.index]\n",
    "\n",
    "#----read FMBA data------\n",
    "FMBA_data=pd.read_csv(\"../CDR3_code/BLOSUM62/UNWEIGHT_TABLES/FMBA_top_2000AA/FMBA_top_10000AA.tsv\",\n",
    "                    sep=\"\\t\", index_col=0)\n",
    "FMBA_data.index=list(map(lambda x: x[0 : (x.rfind(\"S\")-1)], FMBA_data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples in data:\n",
      "\n",
      "fmba_set1 394\n",
      "fmba_set1_COVID 147\n",
      "fmba_set1_HEALTHY 247\n",
      "fmba_set2 207\n",
      "fmba_set2_COVID 107\n",
      "fmba_set2_HEALTHY 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daria/.local/lib/python3.6/site-packages/pandas/core/indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/home/daria/.local/lib/python3.6/site-packages/pandas/core/indexing.py:1765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n",
      "/home/daria/.local/lib/python3.6/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adaptive_set1 517\n",
      "adaptive_set1_COVID 397\n",
      "adaptive_set1_HEALTHY 120\n",
      "adaptive_set2 1203\n",
      "adaptive_set2_COVID 541\n",
      "adaptive_set2_HEALTHY 662\n"
     ]
    }
   ],
   "source": [
    "#-----STATUS-----\n",
    "print(\"number of samples in data:\\n\")\n",
    "\n",
    "#-----FMBA data-----\n",
    "FMBA_data_=FMBA_data.loc[FMBA_data.index.isin(fmba_COVID) | FMBA_data.index.isin(fmba_healthy) | FMBA_data.index.isin(fmba_precovid)]\n",
    "FMBA_data_.loc[FMBA_data_.index.isin(fmba_COVID) , \"status\"]=\"COVID\"\n",
    "FMBA_data_.loc[FMBA_data_.index.isin(fmba_healthy) , \"status\"]=\"healthy\"\n",
    "FMBA_data_.loc[FMBA_data_.index.isin(fmba_precovid) , \"status\"]=\"healthy\"\n",
    "fmba_set1=FMBA_data_.loc[FMBA_data_.index.isin(fmba_set1_)]\n",
    "print(\"fmba_set1\", len(fmba_set1))\n",
    "print(\"fmba_set1_COVID\", len(fmba_set1.loc[fmba_set1.index.isin(fmba_COVID) | fmba_set1.index.isin(fmba_precovid)]))\n",
    "print(\"fmba_set1_HEALTHY\", len(fmba_set1.loc[fmba_set1.index.isin(fmba_healthy)]))\n",
    "fmba_set2=FMBA_data_.loc[FMBA_data_.index.isin(fmba_set2_)]\n",
    "print(\"fmba_set2\", len(fmba_set2))\n",
    "print(\"fmba_set2_COVID\", len(fmba_set2.loc[fmba_set2.index.isin(fmba_COVID)]))\n",
    "print(\"fmba_set2_HEALTHY\", len(fmba_set2.loc[fmba_set2.index.isin(fmba_precovid)]))\n",
    "\n",
    "#-----Adaptive data-----\n",
    "AB_data_=AB_data.loc[AB_data.index.isin(adaptive_acute)]\n",
    "AB_data_[\"status\"]=\"COVID\"\n",
    "HIP_data[\"status\"]=\"healthy\"\n",
    "KECK_data[\"status\"]=\"healthy\"\n",
    "AB_data_=pd.concat([AB_data_, HIP_data, KECK_data])\n",
    "adaptive_set1=AB_data_.loc[AB_data_.index.isin(adaptive_set1_)]\n",
    "print(\"adaptive_set1\", len(adaptive_set1))\n",
    "print(\"adaptive_set1_COVID\", len(adaptive_set1.loc[adaptive_set1.index.isin(adaptive_set1_-KECK)]))\n",
    "print(\"adaptive_set1_HEALTHY\", len(adaptive_set1.loc[adaptive_set1.index.isin(KECK)]))\n",
    "adaptive_set2=AB_data_.loc[AB_data_.index.isin(adaptive_set2_)]\n",
    "print(\"adaptive_set2\", len(adaptive_set2))\n",
    "print(\"adaptive_set2_COVID\", len(adaptive_set2.loc[adaptive_set2.index.isin(adaptive_set2_-HIP)]))\n",
    "print(\"adaptive_set2_HEALTHY\", len(adaptive_set2.loc[adaptive_set2.index.isin(HIP)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and test sets:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['fmba_set1/fmba_set2',\n",
       " 'fmba_set1/adaptive_set1',\n",
       " 'fmba_set1/adaptive_set2',\n",
       " 'fmba_set2/fmba_set1',\n",
       " 'fmba_set2/adaptive_set1',\n",
       " 'fmba_set2/adaptive_set2',\n",
       " 'adaptive_set1/fmba_set1',\n",
       " 'adaptive_set1/fmba_set2',\n",
       " 'adaptive_set1/adaptive_set2',\n",
       " 'adaptive_set2/fmba_set1',\n",
       " 'adaptive_set2/fmba_set2',\n",
       " 'adaptive_set2/adaptive_set1']"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-----combinations of training and test sets-----\n",
    "model_permutation_=list(permutations((\"fmba_set1\",\"fmba_set2\", \"adaptive_set1\",\"adaptive_set2\"), 2))\n",
    "model_permutation=[]\n",
    "for i in range(len(model_permutation_)):\n",
    "    x, y =iter(model_permutation_[i])\n",
    "    model_permutation.append(f'{x}/{y}')\n",
    "\n",
    "print(\"training and test sets:\\n\")\n",
    "model_permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----SVM------\n",
    "output_folder=\"model_comparison/\"\n",
    "output_file=output_folder+\"/\"+\"model_comparison.tsv\"\n",
    "\n",
    "parameters = {\"C\": [0.01, 0.5, 1], \"kernel\": [\"linear\", \"rbf\"], \"degree\": [1, 2, 3], \"gamma\": [\"scale\"]} \n",
    "column_names=[*[\"normalization\", \"features\", \"mismatch\", \"weight\"], *model_permutation]\n",
    "datasets=list(permutations((fmba_set1, fmba_set2, adaptive_set1, adaptive_set2), 2))\n",
    "\n",
    "def run_classifier(normalization, features, mismatch, weight,\n",
    "                   datasets=datasets, parameters=parameters, column_names=column_names,\n",
    "                   output_folder=output_folder, output_file=output_file):   \n",
    "    scores=[]\n",
    "    best_parameters=[]\n",
    "    for dataset in datasets:\n",
    "        train_set, test_set=iter(dataset)\n",
    "#------split into features matrix X and vector with ansvers y-----\n",
    "        X_to_fit=train_set[train_set.columns[~train_set.columns.isin([\"status\"])]]\n",
    "        y_to_fit=train_set[\"status\"]\n",
    "        X_test=test_set[test_set.columns[~test_set.columns.isin([\"status\"])]]\n",
    "        y_test=test_set[\"status\"]\n",
    "#-----find hyperparameters----\n",
    "        clf=RandomizedSearchCV(SVC(class_weight=\"balanced\"), parameters, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "        clf.fit(X_to_fit, y_to_fit)\n",
    "        #-----best estimator-----\n",
    "        SVM=clf.best_estimator_\n",
    "        best_parameter=clf.best_params_\n",
    "        best_parameters.append(best_parameter)\n",
    "        y_pred=SVM.predict(X_test)\n",
    "        score=SVM.score(X_test, y_test)\n",
    "        scores.append(score)\n",
    "    scores_and_features=[*[normalization, features, mismatch, weight], *scores]   \n",
    "#-----make output file, if it doesn't exist-----\n",
    "    try:\n",
    "        os.mkdir(output_folder)\n",
    "        with open(output_file,\"w\") as out_file:\n",
    "            out_file.write(\"\\t\".join(column_names))\n",
    "    except:\n",
    "        pass\n",
    "    #-----write a string to a file-----\n",
    "    with open(output_file,\"a\") as out_file:\n",
    "            out_file.write(\"\\n\")\n",
    "            out_file.write(\"\\t\".join(str(xT) for xT in scores_and_features)) \n",
    "    return best_parameters         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----RANDOM FOREST-----\n",
    "output_folder=\"model_comparison/\"\n",
    "output_file=output_folder+\"/\"+\"model_comparison.tsv\"\n",
    "\n",
    "parameters = {'criterion': ['gini'], 'max_depth' : [3, 5, 7], 'min_samples_leaf': [4, 10, 20],\n",
    "               'min_samples_split': [10, 20, 40], 'max_features': [15, 20, 50]}\n",
    "column_names=[*[\"normalization\", \"features\", \"mismatch\", \"weight\"], *model_permutation]\n",
    "datasets=list(permutations((fmba_set1, fmba_set2, adaptive_set1, adaptive_set2), 2))\n",
    "\n",
    "def run_classifier(normalization, features, mismatch, weight,\n",
    "                   datasets=datasets, parameters=parameters, column_names=column_names,\n",
    "                   output_folder=output_folder, output_file=output_file):   \n",
    "    scores=[]\n",
    "    best_parameters=[]\n",
    "    for dataset in datasets:\n",
    "        train_set, test_set=iter(dataset)\n",
    "#------split into features matrix X and vector with ansvers y-----\n",
    "        X_to_fit=train_set[train_set.columns[~train_set.columns.isin([\"status\"])]]\n",
    "        y_to_fit=train_set[\"status\"]\n",
    "        X_test=test_set[test_set.columns[~test_set.columns.isin([\"status\"])]]\n",
    "        y_test=test_set[\"status\"]\n",
    "#-----find hyperparameters----\n",
    "        clf=RandomizedSearchCV(RandomForestClassifier(class_weight=\"balanced\"), parameters, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "        clf.fit(X_to_fit, y_to_fit)\n",
    "        #-----best estimator-----\n",
    "        RF=clf.best_estimator_\n",
    "        best_parameter=clf.best_params_\n",
    "        best_parameters.append(best_parameter)\n",
    "        y_pred=RF.predict(X_test)\n",
    "        score=RF.score(X_test, y_test)\n",
    "        scores.append(score)\n",
    "    scores_and_features=[*[normalization, features, mismatch, weight], *scores]   \n",
    "#-----make output file, if it doesn't exist-----\n",
    "    try:\n",
    "        os.mkdir(output_folder)\n",
    "        with open(output_file,\"w\") as out_file:\n",
    "            out_file.write(\"\\t\".join(column_names))\n",
    "    except:\n",
    "        pass\n",
    "    #-----write a string to a file-----\n",
    "    with open(output_file,\"a\") as out_file:\n",
    "            out_file.write(\"\\n\")\n",
    "            out_file.write(\"\\t\".join(str(xT) for xT in scores_and_features)) \n",
    "    return best_parameters         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daria/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 81 is smaller than n_iter=100. Running 81 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 243 out of 243 | elapsed:    8.4s finished\n",
      "/home/daria/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 81 is smaller than n_iter=100. Running 81 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 243 out of 243 | elapsed:    4.8s finished\n",
      "/home/daria/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 81 is smaller than n_iter=100. Running 81 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 243 out of 243 | elapsed:    4.9s finished\n",
      "/home/daria/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 81 is smaller than n_iter=100. Running 81 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 243 out of 243 | elapsed:    4.4s finished\n",
      "/home/daria/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 81 is smaller than n_iter=100. Running 81 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 243 out of 243 | elapsed:    4.1s finished\n",
      "/home/daria/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 81 is smaller than n_iter=100. Running 81 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 243 out of 243 | elapsed:    4.6s finished\n",
      "/home/daria/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 81 is smaller than n_iter=100. Running 81 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 243 out of 243 | elapsed:    5.1s finished\n",
      "/home/daria/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 81 is smaller than n_iter=100. Running 81 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 243 out of 243 | elapsed:    5.5s finished\n",
      "/home/daria/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 81 is smaller than n_iter=100. Running 81 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 243 out of 243 | elapsed:    5.4s finished\n",
      "/home/daria/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 81 is smaller than n_iter=100. Running 81 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 243 out of 243 | elapsed:    8.5s finished\n",
      "/home/daria/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 81 is smaller than n_iter=100. Running 81 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 243 out of 243 | elapsed:    8.6s finished\n",
      "/home/daria/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 81 is smaller than n_iter=100. Running 81 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 243 out of 243 | elapsed:    8.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'min_samples_split': 20,\n",
       "  'min_samples_leaf': 20,\n",
       "  'max_features': 20,\n",
       "  'max_depth': 5,\n",
       "  'criterion': 'gini'},\n",
       " {'min_samples_split': 40,\n",
       "  'min_samples_leaf': 4,\n",
       "  'max_features': 20,\n",
       "  'max_depth': 3,\n",
       "  'criterion': 'gini'},\n",
       " {'min_samples_split': 20,\n",
       "  'min_samples_leaf': 20,\n",
       "  'max_features': 20,\n",
       "  'max_depth': 7,\n",
       "  'criterion': 'gini'},\n",
       " {'min_samples_split': 20,\n",
       "  'min_samples_leaf': 4,\n",
       "  'max_features': 15,\n",
       "  'max_depth': 7,\n",
       "  'criterion': 'gini'},\n",
       " {'min_samples_split': 20,\n",
       "  'min_samples_leaf': 4,\n",
       "  'max_features': 15,\n",
       "  'max_depth': 3,\n",
       "  'criterion': 'gini'},\n",
       " {'min_samples_split': 40,\n",
       "  'min_samples_leaf': 4,\n",
       "  'max_features': 15,\n",
       "  'max_depth': 3,\n",
       "  'criterion': 'gini'},\n",
       " {'min_samples_split': 20,\n",
       "  'min_samples_leaf': 4,\n",
       "  'max_features': 50,\n",
       "  'max_depth': 3,\n",
       "  'criterion': 'gini'},\n",
       " {'min_samples_split': 40,\n",
       "  'min_samples_leaf': 4,\n",
       "  'max_features': 50,\n",
       "  'max_depth': 7,\n",
       "  'criterion': 'gini'},\n",
       " {'min_samples_split': 20,\n",
       "  'min_samples_leaf': 20,\n",
       "  'max_features': 50,\n",
       "  'max_depth': 5,\n",
       "  'criterion': 'gini'},\n",
       " {'min_samples_split': 20,\n",
       "  'min_samples_leaf': 10,\n",
       "  'max_features': 20,\n",
       "  'max_depth': 7,\n",
       "  'criterion': 'gini'},\n",
       " {'min_samples_split': 20,\n",
       "  'min_samples_leaf': 10,\n",
       "  'max_features': 15,\n",
       "  'max_depth': 7,\n",
       "  'criterion': 'gini'},\n",
       " {'min_samples_split': 10,\n",
       "  'min_samples_leaf': 4,\n",
       "  'max_features': 20,\n",
       "  'max_depth': 7,\n",
       "  'criterion': 'gini'}]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_classifier(normalization=\"top-2000 public\", features=\"public clonotypes\", mismatch=\"blosum\", weight=\"unweighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalization</th>\n",
       "      <th>features</th>\n",
       "      <th>mismatch</th>\n",
       "      <th>weight</th>\n",
       "      <th>fmba_set1/fmba_set2</th>\n",
       "      <th>fmba_set1/adaptive_set1</th>\n",
       "      <th>fmba_set1/adaptive_set2</th>\n",
       "      <th>fmba_set2/fmba_set1</th>\n",
       "      <th>fmba_set2/adaptive_set1</th>\n",
       "      <th>fmba_set2/adaptive_set2</th>\n",
       "      <th>adaptive_set1/fmba_set1</th>\n",
       "      <th>adaptive_set1/fmba_set2</th>\n",
       "      <th>adaptive_set1/adaptive_set2</th>\n",
       "      <th>adaptive_set2/fmba_set1</th>\n",
       "      <th>adaptive_set2/fmba_set2</th>\n",
       "      <th>adaptive_set2/adaptive_set1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>top-5000</td>\n",
       "      <td>enriched in COVID</td>\n",
       "      <td>single mismatch</td>\n",
       "      <td>weighted</td>\n",
       "      <td>0.859903</td>\n",
       "      <td>0.802708</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>0.685279</td>\n",
       "      <td>0.996132</td>\n",
       "      <td>0.942643</td>\n",
       "      <td>0.626904</td>\n",
       "      <td>0.483092</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.626904</td>\n",
       "      <td>0.483092</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>top-5000</td>\n",
       "      <td>enriched in COVID</td>\n",
       "      <td>single mismatch</td>\n",
       "      <td>unweighted</td>\n",
       "      <td>0.827206</td>\n",
       "      <td>0.647687</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.633205</td>\n",
       "      <td>0.770463</td>\n",
       "      <td>0.484452</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.621324</td>\n",
       "      <td>0.495090</td>\n",
       "      <td>0.469112</td>\n",
       "      <td>0.595588</td>\n",
       "      <td>0.718861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>top-5000</td>\n",
       "      <td>public clonotypes</td>\n",
       "      <td>single mismatch</td>\n",
       "      <td>weighted</td>\n",
       "      <td>0.878676</td>\n",
       "      <td>0.854093</td>\n",
       "      <td>0.653028</td>\n",
       "      <td>0.604247</td>\n",
       "      <td>0.761566</td>\n",
       "      <td>0.405074</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.621324</td>\n",
       "      <td>0.811784</td>\n",
       "      <td>0.484556</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.884342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>top-5000</td>\n",
       "      <td>public clonotypes</td>\n",
       "      <td>single mismatch</td>\n",
       "      <td>unweighted</td>\n",
       "      <td>0.871324</td>\n",
       "      <td>0.807829</td>\n",
       "      <td>0.707038</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.750890</td>\n",
       "      <td>0.711948</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.621324</td>\n",
       "      <td>0.853519</td>\n",
       "      <td>0.430502</td>\n",
       "      <td>0.602941</td>\n",
       "      <td>0.898577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>top-2000 public</td>\n",
       "      <td>enriched in COVID</td>\n",
       "      <td>single mismatch</td>\n",
       "      <td>weighted</td>\n",
       "      <td>0.850242</td>\n",
       "      <td>0.649903</td>\n",
       "      <td>0.446384</td>\n",
       "      <td>0.703046</td>\n",
       "      <td>0.740812</td>\n",
       "      <td>0.440565</td>\n",
       "      <td>0.373096</td>\n",
       "      <td>0.516908</td>\n",
       "      <td>0.733167</td>\n",
       "      <td>0.403553</td>\n",
       "      <td>0.463768</td>\n",
       "      <td>0.878143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>top-2000 public</td>\n",
       "      <td>enriched in COVID</td>\n",
       "      <td>single mismatch</td>\n",
       "      <td>unweighted</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.518703</td>\n",
       "      <td>0.675127</td>\n",
       "      <td>0.657640</td>\n",
       "      <td>0.419784</td>\n",
       "      <td>0.373096</td>\n",
       "      <td>0.516908</td>\n",
       "      <td>0.553616</td>\n",
       "      <td>0.436548</td>\n",
       "      <td>0.487923</td>\n",
       "      <td>0.808511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>top-2000 public</td>\n",
       "      <td>public clonotypes</td>\n",
       "      <td>single mismatch</td>\n",
       "      <td>weighted</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.742747</td>\n",
       "      <td>0.458022</td>\n",
       "      <td>0.667513</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>0.469659</td>\n",
       "      <td>0.373096</td>\n",
       "      <td>0.516908</td>\n",
       "      <td>0.812136</td>\n",
       "      <td>0.444162</td>\n",
       "      <td>0.328502</td>\n",
       "      <td>0.856867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>top-2000 public</td>\n",
       "      <td>public clonotypes</td>\n",
       "      <td>single mismatch</td>\n",
       "      <td>unweighted</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.775629</td>\n",
       "      <td>0.470490</td>\n",
       "      <td>0.687817</td>\n",
       "      <td>0.758221</td>\n",
       "      <td>0.746467</td>\n",
       "      <td>0.373096</td>\n",
       "      <td>0.516908</td>\n",
       "      <td>0.814630</td>\n",
       "      <td>0.373096</td>\n",
       "      <td>0.483092</td>\n",
       "      <td>0.870406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>full repertoire</td>\n",
       "      <td>public clonotypes</td>\n",
       "      <td>without mismatch</td>\n",
       "      <td>weighted</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.221477</td>\n",
       "      <td>0.540650</td>\n",
       "      <td>0.572337</td>\n",
       "      <td>0.243289</td>\n",
       "      <td>0.545528</td>\n",
       "      <td>0.454690</td>\n",
       "      <td>0.680124</td>\n",
       "      <td>0.481301</td>\n",
       "      <td>0.453100</td>\n",
       "      <td>0.686335</td>\n",
       "      <td>0.887584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>full repertoire</td>\n",
       "      <td>public clonotypes</td>\n",
       "      <td>without mismatch</td>\n",
       "      <td>unweighted</td>\n",
       "      <td>0.838509</td>\n",
       "      <td>0.224832</td>\n",
       "      <td>0.541463</td>\n",
       "      <td>0.562798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.548780</td>\n",
       "      <td>0.454690</td>\n",
       "      <td>0.680124</td>\n",
       "      <td>0.581301</td>\n",
       "      <td>0.454690</td>\n",
       "      <td>0.680124</td>\n",
       "      <td>0.753356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>top-2000 public</td>\n",
       "      <td>public clonotypes</td>\n",
       "      <td>group identical aa</td>\n",
       "      <td>weighted</td>\n",
       "      <td>0.772947</td>\n",
       "      <td>0.580271</td>\n",
       "      <td>0.556941</td>\n",
       "      <td>0.644670</td>\n",
       "      <td>0.777563</td>\n",
       "      <td>0.456359</td>\n",
       "      <td>0.373096</td>\n",
       "      <td>0.536232</td>\n",
       "      <td>0.830424</td>\n",
       "      <td>0.380711</td>\n",
       "      <td>0.507246</td>\n",
       "      <td>0.907157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>top-2000 public</td>\n",
       "      <td>public clonotypes</td>\n",
       "      <td>group identical aa</td>\n",
       "      <td>unweighted</td>\n",
       "      <td>0.816425</td>\n",
       "      <td>0.630561</td>\n",
       "      <td>0.565254</td>\n",
       "      <td>0.670051</td>\n",
       "      <td>0.804642</td>\n",
       "      <td>0.518703</td>\n",
       "      <td>0.373096</td>\n",
       "      <td>0.516908</td>\n",
       "      <td>0.804655</td>\n",
       "      <td>0.373096</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.891683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>top-2000 public</td>\n",
       "      <td>public clonotypes</td>\n",
       "      <td>blosum</td>\n",
       "      <td>weighted</td>\n",
       "      <td>0.874396</td>\n",
       "      <td>0.793037</td>\n",
       "      <td>0.526185</td>\n",
       "      <td>0.672589</td>\n",
       "      <td>0.733075</td>\n",
       "      <td>0.571072</td>\n",
       "      <td>0.373096</td>\n",
       "      <td>0.516908</td>\n",
       "      <td>0.765586</td>\n",
       "      <td>0.416244</td>\n",
       "      <td>0.328502</td>\n",
       "      <td>0.849130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>top-2000 public</td>\n",
       "      <td>public clonotypes</td>\n",
       "      <td>blosum</td>\n",
       "      <td>unweighted</td>\n",
       "      <td>0.879227</td>\n",
       "      <td>0.823985</td>\n",
       "      <td>0.450540</td>\n",
       "      <td>0.667513</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.525353</td>\n",
       "      <td>0.373096</td>\n",
       "      <td>0.516908</td>\n",
       "      <td>0.789692</td>\n",
       "      <td>0.413706</td>\n",
       "      <td>0.299517</td>\n",
       "      <td>0.860735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      normalization           features            mismatch      weight  \\\n",
       "0          top-5000  enriched in COVID     single mismatch    weighted   \n",
       "1          top-5000  enriched in COVID     single mismatch  unweighted   \n",
       "2          top-5000  public clonotypes     single mismatch    weighted   \n",
       "3          top-5000  public clonotypes     single mismatch  unweighted   \n",
       "4   top-2000 public  enriched in COVID     single mismatch    weighted   \n",
       "5   top-2000 public  enriched in COVID     single mismatch  unweighted   \n",
       "6   top-2000 public  public clonotypes     single mismatch    weighted   \n",
       "7   top-2000 public  public clonotypes     single mismatch  unweighted   \n",
       "8   full repertoire  public clonotypes    without mismatch    weighted   \n",
       "9   full repertoire  public clonotypes    without mismatch  unweighted   \n",
       "10  top-2000 public  public clonotypes  group identical aa    weighted   \n",
       "11  top-2000 public  public clonotypes  group identical aa  unweighted   \n",
       "12  top-2000 public  public clonotypes              blosum    weighted   \n",
       "13  top-2000 public  public clonotypes              blosum  unweighted   \n",
       "\n",
       "    fmba_set1/fmba_set2  fmba_set1/adaptive_set1  fmba_set1/adaptive_set2  \\\n",
       "0              0.859903                 0.802708                 0.507066   \n",
       "1              0.827206                 0.647687                 0.576923   \n",
       "2              0.878676                 0.854093                 0.653028   \n",
       "3              0.871324                 0.807829                 0.707038   \n",
       "4              0.850242                 0.649903                 0.446384   \n",
       "5              0.855072                 0.727273                 0.518703   \n",
       "6              0.855072                 0.742747                 0.458022   \n",
       "7              0.855072                 0.775629                 0.470490   \n",
       "8              0.869565                 0.221477                 0.540650   \n",
       "9              0.838509                 0.224832                 0.541463   \n",
       "10             0.772947                 0.580271                 0.556941   \n",
       "11             0.816425                 0.630561                 0.565254   \n",
       "12             0.874396                 0.793037                 0.526185   \n",
       "13             0.879227                 0.823985                 0.450540   \n",
       "\n",
       "    fmba_set2/fmba_set1  fmba_set2/adaptive_set1  fmba_set2/adaptive_set2  \\\n",
       "0              0.685279                 0.996132                 0.942643   \n",
       "1              0.633205                 0.770463                 0.484452   \n",
       "2              0.604247                 0.761566                 0.405074   \n",
       "3              0.648649                 0.750890                 0.711948   \n",
       "4              0.703046                 0.740812                 0.440565   \n",
       "5              0.675127                 0.657640                 0.419784   \n",
       "6              0.667513                 0.744681                 0.469659   \n",
       "7              0.687817                 0.758221                 0.746467   \n",
       "8              0.572337                 0.243289                 0.545528   \n",
       "9              0.562798                 0.250000                 0.548780   \n",
       "10             0.644670                 0.777563                 0.456359   \n",
       "11             0.670051                 0.804642                 0.518703   \n",
       "12             0.672589                 0.733075                 0.571072   \n",
       "13             0.667513                 0.680851                 0.525353   \n",
       "\n",
       "    adaptive_set1/fmba_set1  adaptive_set1/fmba_set2  \\\n",
       "0                  0.626904                 0.483092   \n",
       "1                  0.432432                 0.621324   \n",
       "2                  0.432432                 0.621324   \n",
       "3                  0.432432                 0.621324   \n",
       "4                  0.373096                 0.516908   \n",
       "5                  0.373096                 0.516908   \n",
       "6                  0.373096                 0.516908   \n",
       "7                  0.373096                 0.516908   \n",
       "8                  0.454690                 0.680124   \n",
       "9                  0.454690                 0.680124   \n",
       "10                 0.373096                 0.536232   \n",
       "11                 0.373096                 0.516908   \n",
       "12                 0.373096                 0.516908   \n",
       "13                 0.373096                 0.516908   \n",
       "\n",
       "    adaptive_set1/adaptive_set2  adaptive_set2/fmba_set1  \\\n",
       "0                      1.000000                 0.626904   \n",
       "1                      0.495090                 0.469112   \n",
       "2                      0.811784                 0.484556   \n",
       "3                      0.853519                 0.430502   \n",
       "4                      0.733167                 0.403553   \n",
       "5                      0.553616                 0.436548   \n",
       "6                      0.812136                 0.444162   \n",
       "7                      0.814630                 0.373096   \n",
       "8                      0.481301                 0.453100   \n",
       "9                      0.581301                 0.454690   \n",
       "10                     0.830424                 0.380711   \n",
       "11                     0.804655                 0.373096   \n",
       "12                     0.765586                 0.416244   \n",
       "13                     0.789692                 0.413706   \n",
       "\n",
       "    adaptive_set2/fmba_set2  adaptive_set2/adaptive_set1  \n",
       "0                  0.483092                     1.000000  \n",
       "1                  0.595588                     0.718861  \n",
       "2                  0.426471                     0.884342  \n",
       "3                  0.602941                     0.898577  \n",
       "4                  0.463768                     0.878143  \n",
       "5                  0.487923                     0.808511  \n",
       "6                  0.328502                     0.856867  \n",
       "7                  0.483092                     0.870406  \n",
       "8                  0.686335                     0.887584  \n",
       "9                  0.680124                     0.753356  \n",
       "10                 0.507246                     0.907157  \n",
       "11                 0.521739                     0.891683  \n",
       "12                 0.328502                     0.849130  \n",
       "13                 0.299517                     0.860735  "
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"model_comparison/model_comparison.tsv\", sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
